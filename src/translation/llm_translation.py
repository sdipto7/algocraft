import os
from openai import OpenAI
import logging
from pathlib import Path
from dotenv import load_dotenv
import re
import argparse
from tqdm import tqdm
from arg_validator import validate_arguments

os.makedirs(f'logs', exist_ok=True)
logging.basicConfig(filename=f"logs/translation.log", level=logging.INFO, format='%(asctime)s %(levelname)s %(module)s - %(funcName)s: %(message)s', datefmt='%Y-%m-%d %H:%M:%S')

class Translator:
    EXTENSTIONS = {
        "Java": "java",
        "Python": "py"
    }

    MODEL_ENV_MAP = {
        "gpt-4o": "GPT_MODEL",
        "llama-4-maverick": "LLAMA_MODEL",
        "gemini-flash-1.5": "GEMINI_MODEL",
        "deepseek-r1": "DEEPSEEK_MODEL"
    }

    def __init__(self, model, dataset) -> None:
        self.dataset = dataset
        self.base_url = os.getenv("BASE_URL")
        self.api_key = os.getenv("API_KEY")
        self.model = os.getenv(MODEL_ENV_MAP.get(model))

    def __enter__(self):
        logging.info(f"successfully set up openai api key")

        self.main_dir = os.getcwd()
        self.input_dir = Path(self.main_dir).joinpath("dataset", self.dataset)
        self.output_dir = os.path.join(self.main_dir, "output")

        if not self.input_dir.exists():
            logging.error(f"directory {str(self.input_dir)} does not exist. raising FileNotFoundError")
            raise FileNotFoundError(f"Directory {str(self.input_dir)} does not exist.")

        self.out_dir = Path(self.output_dir).joinpath(self.model, self.dataset)
        if not self.out_dir.exists():
            self.out_dir.mkdir(parents=True)

        return self

    def generate_response_with_openai(self, message_log):
        client = OpenAI(
            base_url=self.base_url,
            api_key=self.api_key,
        )

        response = "exceptional case"
        is_success = False
        max_attempts = 5
        while max_attempts > 0:
            try:
                response = client.chat.completions.create(
                    model=self.model,
                    messages=message_log,
                    temperature=0.7,
                )
                is_success = True
                break
            except Exception as e:
                return "# Token size exceeded."
            except:
                max_attempts -= 1
                continue

        if not is_success:
            return response

        for choice in response.choices:
            if "text" in choice:
                return choice.text

        return response.choices[0].message.content

    def get_algorithm_from_source_code(self, source_code_as_str, source_lang):
        logging.info(f"Generating algorithm from the given {source_lang} code")

        content = source_code_as_str + f"\n# Generate only the step by step algorithm for the above {source_lang} code. Print only the steps and exclude comments, headers, explanation and examples.\n"

        message = [
            {"role": "system", "content": "You are a helpful assistant."},
            {"role": "user", "content": content}
        ]
        
        return self.generate_response_with_openai(message)
    
    def get_translated_code_from_algorithm(self, algorithm, target_lang):
        logging.info(f"Generating {target_lang} code with the algorithm generated by openai")

        content = algorithm + f"\n# Using the above algorithm, generate the equivalent {target_lang} code. Exclude any comments, headers, explanation and examples.\n"

        message = [
            {"role": "system", "content": "You are a helpful assistant."},
            {"role": "user", "content": content}
        ]
        
        response = self.generate_response_with_openai(message)

        return response.replace(f"```{target_lang.lower()}", "").replace("```", "")
    
    def get_algorithm_based_translated_code(self, source_code_as_str, source_lang, target_lang):
        algorithm = self.get_algorithm_from_source_code(source_code_as_str, source_lang)
        translated_code = self.get_translated_code_from_algorithm(algorithm, target_lang)

        return translated_code
    
    def get_translated_code_from_source_code(self, source_code_as_str, source_lang, target_lang):
        logging.info(f"Generating {target_lang} code based on the given {source_lang} code using openai")

        content = source_code_as_str + f"\n# Translate the above {source_lang} code to {target_lang}. Print only the {target_lang} code and end with the comment \"End of Code\".\n"

        message = [
            {"role": "system", "content": "You are a helpful assistant."},
            {"role": "user", "content": content}
        ]
        
        response = self.generate_response_with_openai(message)

        return response.replace(f"```{target_lang.lower()}", "").replace("```", "")

    def translate(self, source_lang, target_lang, is_algorithm_based_translation):
        snippets = list(self.input_dir.joinpath(str(source_lang), "Code").iterdir())

        for source_file in tqdm(snippets, total=len(snippets), bar_format="{desc:<5.5}{percentage:3.0f}%|{bar:10}{r_bar}"):
            source_code_id = source_file.stem
            source_code_as_str = source_file.read_text(encoding="utf-8")

            target_dir = self.out_dir.joinpath(f"{source_lang}", f"{target_lang}")
            if not target_dir.exists():
                target_dir.mkdir(parents=True)

            filename_of_translated_code = target_dir.joinpath(f"{source_code_id}.{Translator.EXTENSTIONS[target_lang]}")

            translated_code_fp = Path(filename_of_translated_code)
            if translated_code_fp.exists():
                continue

            if is_algorithm_based_translation:
                logging.info(f"Executing algorithm based translation")
                translated_code = self.get_algorithm_based_translated_code(source_code_as_str, source_lang, target_lang)
            else:
                logging.info(f"Executing direct source code translation")
                translated_code = self.get_translated_code_from_source_code(source_code_as_str, source_lang, target_lang)

            translated_code = re.sub('public\s*class\s*.+', 'public class ' + source_code_id + ' {', translated_code)

            if self.dataset == 'evalplus' and target_lang == 'Java':
                translated_code = 'package com.example;\n' + translated_code

            with open(filename_of_translated_code, "w") as f:
                print(translated_code, file=f)
                    
    def __exit__(self, exception, _, __):
        print(exception)


if __name__ == "__main__":

    load_dotenv(override=True)

    parser = argparse.ArgumentParser()
    parser.add_argument('--model', help='model to use for code translation. should be one of [gpt-4o, deepseek-r1, gemini-flash-1.5, llama-4-maverick]', required=True, type=str)
    parser.add_argument('--dataset', help='dataset to use for code translation. should be one of [codenet,avatar,evalplus]', required=True, type=str)
    parser.add_argument('--source_lang', help='source language to use for code translation. should be one of [Python,Java]', required=True, type=str)
    parser.add_argument('--target_lang', help='target language to use for code translation. should be one of [Python,Java]', required=True, type=str)
    
    args = parser.parse_args()
    validate_arguments(args)

    model = args.model
    dataset = args.dataset
    source_lang = args.source_lang
    target_lang = args.target_lang

    with Translator(model, dataset) as translator:
        logging.info(f"translating examples with {model} from {source_lang} to {target_lang} using {dataset} dataset")
        translator.translate(source_lang, target_lang, is_algorithm_based_translation=True)
