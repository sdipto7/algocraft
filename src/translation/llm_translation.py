import os
from openai import OpenAI
import logging
from pathlib import Path
from dotenv import load_dotenv
import re
import argparse
from tqdm import tqdm
import pandas as pd
import sys
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(__file__))))
from src.validator.arg_validator import validate_arguments
from src.helper.model_path_helper import resolve_model_name_for_path
from src.util.constants import get_extension_map, get_model_env_map

os.makedirs(f'logs', exist_ok=True)
logging.basicConfig(filename=f"logs/translation.log", level=logging.INFO, format='%(asctime)s %(levelname)s %(module)s - %(funcName)s: %(message)s', datefmt='%Y-%m-%d %H:%M:%S')

class Translator:
    def __init__(self, model, dataset) -> None:
        self.dataset = dataset
        self.base_url = os.getenv("BASE_URL")
        self.api_key = os.getenv("API_KEY")
        self.model = os.getenv(get_model_env_map().get(model))

    def __enter__(self):
        self.main_dir = os.getcwd()
        self.input_dir = Path(self.main_dir).joinpath("dataset", self.dataset)
        self.output_dir = os.path.join(self.main_dir, "output")

        if not self.input_dir.exists():
            logging.error(f"directory {str(self.input_dir)} does not exist. raising FileNotFoundError")
            raise FileNotFoundError(f"Directory {str(self.input_dir)} does not exist.")

        return self

    def generate_response_with_openai(self, message_log):
        client = OpenAI(
            base_url=self.base_url,
            api_key=self.api_key,
        )

        response = "exceptional case"
        is_success = False
        max_attempts = 5
        while max_attempts > 0:
            try:
                response = client.chat.completions.create(
                    model=self.model,
                    messages=message_log,
                    temperature=0.7,
                )
                is_success = True
                break
            except Exception as e:
                return "# Token size exceeded."
            except:
                max_attempts -= 1
                continue

        if not is_success:
            return response

        for choice in response.choices:
            if "text" in choice:
                return choice.text

        return response.choices[0].message.content

    def get_algorithm_from_source_code(self, source_code_as_str, source_lang):
        logging.info(f"Generating algorithm from the given {source_lang} code")

        content = source_code_as_str + f"\n# Generate only the step by step algorithm for the above {source_lang} code. Print only the steps and exclude comments, headers, explanation and examples.\n"

        message = [
            {"role": "system", "content": "You are a helpful assistant."},
            {"role": "user", "content": content}
        ]
        
        return self.generate_response_with_openai(message)
    
    def get_translated_code_from_algorithm(self, algorithm, target_lang):
        logging.info(f"Generating {target_lang} code with the algorithm generated by openai")

        content = algorithm + f"\n# Using the above algorithm, generate the equivalent {target_lang} code. Exclude any comments, headers, explanation and examples.\n"

        message = [
            {"role": "system", "content": "You are a helpful assistant."},
            {"role": "user", "content": content}
        ]
        
        response = self.generate_response_with_openai(message)

        return response.replace(f"```{target_lang.lower()}", "").replace("```", "")
    
    def get_algorithm_based_translated_code(self, source_code_as_str, source_lang, target_lang):
        algorithm = self.get_algorithm_from_source_code(source_code_as_str, source_lang)
        translated_code = self.get_translated_code_from_algorithm(algorithm, target_lang)

        return algorithm, translated_code
    
    def get_direct_translated_code(self, source_code_as_str, source_lang, target_lang):
        logging.info(f"Generating {target_lang} code based on the given {source_lang} code using openai")

        content = source_code_as_str + f"\n# Translate the above {source_lang} code to {target_lang}. Print only the {target_lang} code and end with the comment \"End of Code\".\n"

        message = [
            {"role": "system", "content": "You are a helpful assistant."},
            {"role": "user", "content": content}
        ]
        
        response = self.generate_response_with_openai(message)

        return response.replace(f"```{target_lang.lower()}", "").replace("```", "")

    def get_algorithm_dir(self, base_dir_path):
        algorithm_dir = Path(base_dir_path).joinpath("algorithm")
        algorithm_dir.mkdir(parents=True, exist_ok=True)        
        
        return algorithm_dir

    def get_translated_code_dir(self, base_dir_path, target_lang):
        translated_code_dir = Path(base_dir_path).joinpath(f"{target_lang}")
        translated_code_dir.mkdir(parents=True, exist_ok=True)
        
        return translated_code_dir

    def write_to_file(self, file_name, content):
        logging.info(f"Writing to file {file_name}")

        with open(file_name, "w") as f:
            print(content, file=f)

        logging.info(f"File {file_name} created successfully")

    def replace_class_name(self, translated_code, source_code_id):
        return re.sub('public\s*class\s*.+', 'public class ' + source_code_id + ' {', translated_code)

    def prepend_package_name_for_evalplus_dataset(self, translated_code, target_lang):
        return 'package com.example;\n' + translated_code if self.dataset == 'evalplus' and target_lang == 'Java' else translated_code

    def refine_translated_code(self, translated_code, source_code_id, target_lang):
        translated_code = self.replace_class_name(translated_code, source_code_id)
        translated_code = self.prepend_package_name_for_evalplus_dataset(translated_code, target_lang)
        
        return translated_code

    def write_to_csv(self, path, columns, data):
        logging.info(f"Writing to csv file {path}")
        
        df = pd.DataFrame(data, columns=columns)
        df.to_csv(path, index=False)

        logging.info(f"CSV file {path} created successfully")

    def translate(self, source_lang, target_lang, is_algorithm_based_translation):
        snippets = list(self.input_dir.joinpath(str(source_lang), "Code").iterdir())

        translation_type_for_path = "algo_based_translation" if is_algorithm_based_translation else "direct_translation"
        model_name_for_path = resolve_model_name_for_path(self.model)
        base_dir_path = Path(self.output_dir).joinpath(translation_type_for_path, model_name_for_path, self.dataset, f"{source_lang}")

        logging.info(f"Executing {'algorithm-based' if is_algorithm_based_translation else 'direct'} source code translation")

        csv_data = []

        for source_file in tqdm(snippets, total=len(snippets), bar_format="{desc:<5.5}{percentage:3.0f}%|{bar:10}{r_bar}"):
            source_code_id = source_file.stem
            source_code_as_str = source_file.read_text(encoding="utf-8")

            translated_code_dir = self.get_translated_code_dir(base_dir_path, target_lang)
            filename_of_translated_code = translated_code_dir.joinpath(f"{source_code_id}.{get_extension_map().get(target_lang)}")

            row_data = {"source_lang": source_lang, "source_code_id": source_code_id, "source_code": source_code_as_str}

            if is_algorithm_based_translation:
                algorithm_dir = self.get_algorithm_dir(base_dir_path)
                filename_of_algorithm = algorithm_dir.joinpath(f"{source_code_id}.txt")

                if any(Path(file).exists() for file in [filename_of_algorithm, filename_of_translated_code]):
                    logging.info(f"Algorithm or translated code already exists for {source_code_id}. Moving to next program.")
                    continue

                algorithm, translated_code = self.get_algorithm_based_translated_code(source_code_as_str, source_lang, target_lang)
                row_data["algorithm"] = algorithm
                
                self.write_to_file(filename_of_algorithm, algorithm)
            
            else:
                if Path(filename_of_translated_code).exists():
                    logging.info(f"Translated code already exists for {source_code_id}. Moving to next program.")                    
                    continue
                
                translated_code = self.get_direct_translated_code(source_code_as_str, source_lang, target_lang)

            translated_code = self.refine_translated_code(translated_code, source_code_id, target_lang)
            row_data.update({"target_lang": target_lang, "translated_code": translated_code})

            csv_data.append(row_data)
            self.write_to_file(filename_of_translated_code, translated_code)

        csv_file_path = base_dir_path.joinpath(f"{source_lang}_to_{target_lang}_translation.csv")
        columns = ["source_lang", "source_code_id", "source_code", "target_lang", "translated_code"]
        if is_algorithm_based_translation:
            columns.insert(3, "algorithm")

        self.write_to_csv(csv_file_path, columns, csv_data)
        
        logging.info("Translation process completed.")

    def __exit__(self, exception, _, __):
        print(exception)


if __name__ == "__main__":

    load_dotenv(override=True)

    parser = argparse.ArgumentParser()
    parser.add_argument('--model', help='model to use for code translation. should be one of [gpt-4o, deepseek-r1, gemini-flash-1.5, llama-4-maverick]', required=True, type=str)
    parser.add_argument('--dataset', help='dataset to use for code translation. should be one of [codenet,avatar,evalplus]', required=True, type=str)
    parser.add_argument('--source_lang', help='source language to use for code translation. should be one of [Python,Java]', required=True, type=str)
    parser.add_argument('--target_lang', help='target language to use for code translation. should be one of [Python,Java]', required=True, type=str)
    
    args = parser.parse_args()
    validate_arguments(args)

    model = args.model
    dataset = args.dataset
    source_lang = args.source_lang
    target_lang = args.target_lang

    with Translator(model, dataset) as translator:
        logging.info(f"translating examples with {model} from {source_lang} to {target_lang} using {dataset} dataset")
        translator.translate(source_lang, target_lang, is_algorithm_based_translation=True)
